package main

func (l1 *LinkedList) SumTwoLists(l2 *LinkedList) *LinkedList {
	if l1 == nil || l2 == nil || l1.Count() != l2.Count() ||
		l2.Count() == 0 || l1.Count() == 0 {
		return nil
	}
	res := &LinkedList{}
	first := l1.head
	second := l2.head
	for first != nil && second != nil {
		newNode := Node{value: first.value + second.value}
		res.AddInTail(&newNode)
		first = first.next
		second = second.next
	}
	return res
}

// Интересная структура данных, разок с ней сталкивался в работе, но тут конечно совершенно другой уровень понимания.
// Для функции очистки использовал простое голов и хвостов (почти самогон), тк в го есть сборщик мусора.
// В языках без такового, конечно, надо было бы проходиться по всем элементам и удалять каждый,
// но здесь это избыточно. Сложно было с функцией удаления, пришлось заводить два указателя, да и длинновато вышло.
// Изначально в функциях использовалась передача по значению, я поменял ее на передачу по ссылке,
// так как с передачей по значению тесты не работали, что, в общем-то логично, учитывая,
// что копия после завершения работы функции удаляется.

// Немного посмотрел алгоритмы с предыдущей работы
// в качестве примера работающий за линейную скорость алгоритм поиска по словарям словарей
// (просто понравилась реализация, нигде до этого не видел)
//
//	def deep_get(dictionary, *keys):
//	return reduce(
//	lambda d, key: d.get(key, None) if isinstance(d, dict) else None,
//	keys,
//	dictionary)
//
// Еще обнаружил стандартную, но занятную ситуацию с функцией поиска объектов с описанием хранилищ отчетов
// и подписей для них - несмотря на сложность O(n^2) (а если учитывать, что на вход принимается список с id отчетов,
// то и O(n^3)), второй и третий цикл гарантирванно отрабатывают не более 2 раз, что делает ситуацию приемлемой.
